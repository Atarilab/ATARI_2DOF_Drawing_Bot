{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 00:11:39.831428: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from drawing_bot_api.trajectory_optimizer.shape_generator import ShapeGenerator\n",
    "from drawing_bot_api.trajectory_optimizer.shape_generator import RESTING_POINT\n",
    "from drawing_bot_api import DrawingBot\n",
    "from drawing_bot_api.trajectory_optimizer.image_processor import ImageProcessor\n",
    "from drawing_bot_api.trajectory_optimizer.wiper import Wiper\n",
    "from drawing_bot_api.trajectory_optimizer.simulator import PatternErrorSim\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from drawing_bot_api.trajectory_optimizer.training_v4 import Trainer\n",
    "import signal\n",
    "from drawing_bot_api.trajectory_optimizer.config import *\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import tensorflow as tf \n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from ipyparallel import Client\n",
    "from multiprocessing import TimeoutError\n",
    "import time\n",
    "import gc\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Display all elements without truncation\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_MODE = False\n",
    "TEST_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit set to \"mm\".\n"
     ]
    }
   ],
   "source": [
    "shape_generator = ShapeGenerator()\n",
    "drawing_bot = DrawingBot()\n",
    "image_processor = ImageProcessor()\n",
    "wiper = Wiper()\n",
    "error_simulator = PatternErrorSim(strength=15, pattern_length=20, seed=1)\n",
    "model = Trainer()\n",
    "reward_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Handlers.SIG_DFL: 0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handler for timeout\n",
    "def handler(signum, frame):\n",
    "    raise TimeoutError(\"Operation timed out\")\n",
    "\n",
    "signal.signal(signal.SIGALRM, handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(data, labels, scale='linear'):\n",
    "    plt.yscale(scale)\n",
    "    for _i in range(len(data)):\n",
    "        plt.plot(data[_i], label=labels[_i])\n",
    "    plt.legend(bbox_to_anchor=(1, 1.15), ncol=3)  \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SHAPE = None\n",
    "if TEST_MODE:\n",
    "    TEST_SHAPE = shape_generator(seed=1)\n",
    "    for shape in TEST_SHAPE:\n",
    "        drawing_bot.add_shape(shape)\n",
    "    TEST_TRAJECTORY = np.array(drawing_bot._get_all_points())\n",
    "    TEST_TEMPLATE = np.array(drawing_bot.plot(training_mode=True, points=TEST_TRAJECTORY))\n",
    "    drawing_bot.shapes.clear()\n",
    "\n",
    "def get_template():\n",
    "    if TEST_MODE:\n",
    "        return TEST_TRAJECTORY, TEST_TEMPLATE\n",
    "    \n",
    "    for shape in shape_generator():\n",
    "        drawing_bot.add_shape(shape)\n",
    "    # get template for drawing\n",
    "    trajectory = np.array(drawing_bot._get_all_points())\n",
    "    template = np.array(drawing_bot.plot(training_mode=True, points=trajectory))\n",
    "    drawing_bot.shapes.clear()\n",
    "    \n",
    "    return trajectory, template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_adjusted_trajectory(trajectory, exploration_factor):\n",
    "    adjusted_trajectory = np.array(model.adjust_trajectory(trajectory, exploration_factor=exploration_factor))\n",
    "    adjusted_template = np.array(drawing_bot.plot(training_mode=True, points=adjusted_trajectory))\n",
    "    return adjusted_trajectory, adjusted_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_drawing(adjusted_trajectory):    \n",
    "    simulated_trajctory = error_simulator(adjusted_trajectory)\n",
    "    drawing = np.array(drawing_bot.plot(training_mode=True, points=simulated_trajctory))\n",
    "    return simulated_trajctory, drawing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_reward(similarity, type='default'):\n",
    "    if type == 'default':\n",
    "        return similarity\n",
    "    \n",
    "    elif type == 'avoid_zero':\n",
    "        THRESHOLD = 0.5\n",
    "        if similarity > THRESHOLD:\n",
    "            return similarity\n",
    "        else:\n",
    "            return (((1-THRESHOLD)/THRESHOLD)*similarity - 1)\n",
    "        \n",
    "    elif type == 'inverted':\n",
    "        return 1 - similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_of_individual_points(trajectory, resolution):\n",
    "    _images = [] \n",
    "    _points = np.array(trajectory)\n",
    "\n",
    "    for _index in range(0, int(len(_points)), resolution):\n",
    "        _images.append(drawing_bot.plot(training_mode=True, points=_points[_index:_index+resolution]))\n",
    "    plt.close('all')\n",
    "    return _images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(template, drawing, train_actor, trajectory, individual_reward=True):\n",
    "    if individual_reward:\n",
    "        resolution = 25\n",
    "        images_of_individual_points = get_images_of_individual_points(trajectory, resolution)\n",
    "        rewards = np.array(image_processor.calc_rewards_for_individual_points(images_of_individual_points, drawing))\n",
    "        rewards = np.repeat(rewards, resolution, axis=0)\n",
    "        rewards = np.nan_to_num(rewards, nan=1)\n",
    "        #rewards = np.append(rewards, np.ones(len(trajectory)-len(rewards)))\n",
    "        advantage, actor_output = model.train(rewards, train_actor)\n",
    "        \n",
    "        del images_of_individual_points\n",
    "\n",
    "        return rewards, advantage, actor_output\n",
    "    else:\n",
    "        similarity = image_processor(template, drawing=drawing)\n",
    "        if similarity is None:\n",
    "            return None\n",
    "        reward = calc_reward(similarity, type='default')\n",
    "        sub_rewards = model.train(reward, train_actor)\n",
    "        return reward, sub_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_visualization(trajectory, rewards, cycle_index, name):\n",
    "    reward_assigned_drawing = drawing_bot.plot(training_mode=True, points=trajectory, color_assignment=rewards)\n",
    "    image_processor.save_image(reward_assigned_drawing, name, f'{name}_visualization', cycle_index)\n",
    "    del reward_assigned_drawing\n",
    "\n",
    "def save_combined_visualization(trajectory, metric1, metric2, reference, cycle_index, name, file_name=None):\n",
    "    if file_name is None: file_name = name \n",
    "    metric1_drawing = drawing_bot.plot(training_mode=True, points=trajectory, color_assignment=metric1)\n",
    "    metric2_drawing = drawing_bot.plot(training_mode=True, points=trajectory, color_assignment=metric2)\n",
    "    image_processor.save_images_combined(metric1_drawing, metric2_drawing, reference, name, file_name, cycle_index)\n",
    "    del metric1_drawing, metric2_drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_cycle(cycle_index, num_of_cycles):\n",
    "    signal.alarm(10)\n",
    "\n",
    "    try:\n",
    "        trajectory, template = get_template()\n",
    "\n",
    "        random_action_prob = 0\n",
    "        RANDOM_CUTOFF = 3000\n",
    "        if cycle_index < RANDOM_CUTOFF:\n",
    "            random_action_prob = RANDOM_ACTION_PROBABILITY * (RANDOM_ACTION_DECAY ** cycle_index) #np.random.random() * (0.005 - (cycle_index/(RANDOM_CUTOFF * 200))) + 0.000001\n",
    "        \n",
    "        train_actor = False\n",
    "        if cycle_index >= 0:\n",
    "            train_actor = True\n",
    "\n",
    "        #print(f'Exploration factor: {exploration_factor}')\n",
    "        adjusted_trajectory, adjusted_template = get_adjusted_trajectory(trajectory, random_action_prob)\n",
    "        simulated_trajectory, drawing = simulate_drawing(adjusted_trajectory)\n",
    "        rewards, advantages, actor_output = fit_model(template, drawing, train_actor, trajectory, individual_reward=True)\n",
    "\n",
    "        if cycle_index % SAVE_IMAGE_FREQ == 0:\n",
    "            #save_assigned_reward_img(simulated_trajectory, advantages, cycle_index, 'advantage')\n",
    "            #save_assigned_reward_img(simulated_trajectory, rewards, cycle_index, 'reward')\n",
    "            _file_name = None #f'rwd_{np.mean(rewards)}__loss_{model.action_mean_log[-1]}'\n",
    "            _rewards = (rewards * 2) - 1\n",
    "            _sigma_values = actor_output[:, :-2]\n",
    "            _sigma_values = model._normalize_to_range_pos(_sigma_values)\n",
    "            _, _simulated_template = simulate_drawing(trajectory)\n",
    "            save_combined_visualization(simulated_trajectory, _sigma_values, advantages, _simulated_template, cycle_index, 'reward_advantage', file_name=_file_name)\n",
    "            image_processor.save_image(drawing, 'original', 'drawing', cycle_index)\n",
    "        \n",
    "        del adjusted_trajectory, adjusted_template, simulated_trajectory, drawing, trajectory, template\n",
    "        \n",
    "        if not rewards is None:\n",
    "            reward_log.append(np.mean(rewards))\n",
    "            print(f'{bcolors.HEADER}Cylce: {cycle_index}\\t{bcolors.ENDC}Random action prob: {random_action_prob}\\t{bcolors.OKCYAN}Reward: {reward_log[-1]}{bcolors.ENDC}')\n",
    "    \n",
    "    except TimeoutError as e:\n",
    "        if DEBUG_MODE:\n",
    "            raise\n",
    "        else:\n",
    "            print(f\"Timeout occurred: {e}\")\n",
    "\n",
    "    finally:\n",
    "        signal.alarm(0)  # Cancel the alarm\n",
    "        if 0:\n",
    "            gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic | mean: 1.729032039642334\tvar: 0.5546128153800964\tmin: 0.4092932939529419\tmax: 3.3769726753234863\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.1490 \n",
      "\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0781 - loss: nan"
     ]
    }
   ],
   "source": [
    "NUM_OF_CYCLES = 300\n",
    "\n",
    "for i in range(NUM_OF_CYCLES):\n",
    "    clear_output(wait=True)\n",
    "    #print(f'Cylce: {i}')\n",
    "    if training_cycle(i, NUM_OF_CYCLES):\n",
    "        break\n",
    "    plt.close('all')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "reward_log = reward_log\n",
    "loss_history_actor = model.loss_actor_log.losses\n",
    "loss_history_critic = model.loss_critic_log.losses\n",
    "critic_mean = model.critic_mean_log\n",
    "critic_var = model.critic_var_log\n",
    "critic_min = model.critic_min_log\n",
    "critic_max = model.critic_max_log\n",
    "\n",
    "\"\"\" #plot rewards and losses\n",
    "reward_log = gaussian_filter1d(reward_log, sigma=1)\n",
    "loss_history_actor = gaussian_filter1d(model.loss_actor_log.losses, sigma=2)\n",
    "loss_history_critic = gaussian_filter1d(model.loss_critic_log.losses, sigma=2)\n",
    "critic_mean = gaussian_filter1d(model.critic_mean_log, sigma=2)\n",
    "critic_var = gaussian_filter1d(model.critic_var_log, sigma=2)\n",
    "critic_min = gaussian_filter1d(model.critic_min_log, sigma=2)\n",
    "critic_max = gaussian_filter1d(model.critic_max_log, sigma=2) \"\"\"\n",
    "\n",
    "end_weights = []\n",
    "for layer in model.critic.layers:\n",
    "    end_weights.append(layer.get_weights()[0])\n",
    "\n",
    "#print(f'\\nInitial weights:\\n{inital_weights}')\n",
    "#print(f'\\n\\nWeights in the end:\\n{end_weights}\\n')\n",
    "\n",
    "plot_graph([loss_history_actor], ['actor loss'], scale='symlog')\n",
    "plot_graph([loss_history_critic], ['critic loss'])\n",
    "plot_graph([reward_log], ['reward'])\n",
    "plot_graph([model.action_mean_log, model.action_max_log, model.action_min_log], ['action average', 'action max', 'action min'])\n",
    "plot_graph([critic_mean, critic_var, critic_min, critic_max], ['Critic mean', 'Critic var', 'Critic min', 'Critic max'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
