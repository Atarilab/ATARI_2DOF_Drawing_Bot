{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 14:13:58.490045: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from drawing_bot_api.trajectory_optimizer.shape_generator import ShapeGenerator\n",
    "from drawing_bot_api.trajectory_optimizer.shape_generator import RESTING_POINT\n",
    "from drawing_bot_api import DrawingBot\n",
    "from drawing_bot_api.trajectory_optimizer.image_processor import ImageProcessor\n",
    "from drawing_bot_api.trajectory_optimizer.wiper import Wiper\n",
    "from drawing_bot_api.trajectory_optimizer.simulator import PatternErrorSim\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from drawing_bot_api.trajectory_optimizer.training_v3 import Trainer\n",
    "import signal\n",
    "from drawing_bot_api.trajectory_optimizer.config import *\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import tensorflow as tf \n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from ipyparallel import Client\n",
    "from multiprocessing import TimeoutError\n",
    "import time\n",
    "import gc\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Display all elements without truncation\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_MODE = False\n",
    "TEST_MODE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit set to \"mm\".\n"
     ]
    }
   ],
   "source": [
    "shape_generator = ShapeGenerator()\n",
    "drawing_bot = DrawingBot()\n",
    "image_processor = ImageProcessor()\n",
    "wiper = Wiper()\n",
    "error_simulator = PatternErrorSim(strength=15, pattern_length=20, seed=1)\n",
    "model = Trainer()\n",
    "reward_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Handlers.SIG_DFL: 0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handler for timeout\n",
    "def handler(signum, frame):\n",
    "    raise TimeoutError(\"Operation timed out\")\n",
    "\n",
    "signal.signal(signal.SIGALRM, handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(data, labels):\n",
    "    for _i in range(len(data)):\n",
    "        plt.plot(data[_i], label=labels[_i])\n",
    "    plt.legend(bbox_to_anchor=(1, 1.15), ncol=3)  \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SHAPE = shape_generator(seed=1)\n",
    "for shape in TEST_SHAPE:\n",
    "    drawing_bot.add_shape(shape)\n",
    "TEST_TRAJECTORY = np.array(drawing_bot._get_all_points())\n",
    "TEST_TEMPLATE = np.array(drawing_bot.plot(training_mode=True, points=TEST_TRAJECTORY))\n",
    "drawing_bot.shapes.clear()\n",
    "\n",
    "def get_template():\n",
    "    if TEST_MODE:\n",
    "        return TEST_TRAJECTORY, TEST_TEMPLATE\n",
    "    \n",
    "    for shape in shape_generator(seed=1):\n",
    "        drawing_bot.add_shape(shape)\n",
    "    # get template for drawing\n",
    "    trajectory = np.array(drawing_bot._get_all_points())\n",
    "    template = np.array(drawing_bot.plot(training_mode=True, points=trajectory))\n",
    "    drawing_bot.shapes.clear()\n",
    "    \n",
    "    return trajectory, template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_adjusted_trajectory(trajectory, exploration_factor):\n",
    "    adjusted_trajectory = np.array(model.adjust_trajectory(trajectory, exploration_factor=exploration_factor))\n",
    "    adjusted_template = np.array(drawing_bot.plot(training_mode=True, points=adjusted_trajectory))\n",
    "    return adjusted_trajectory, adjusted_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_drawing(adjusted_trajectory):    \n",
    "    simulated_trajctory = error_simulator(adjusted_trajectory)\n",
    "    drawing = np.array(drawing_bot.plot(training_mode=True, points=simulated_trajctory))\n",
    "    return simulated_trajctory, drawing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_reward(similarity, type='default'):\n",
    "    if type == 'default':\n",
    "        return similarity\n",
    "    \n",
    "    elif type == 'avoid_zero':\n",
    "        THRESHOLD = 0.5\n",
    "        if similarity > THRESHOLD:\n",
    "            return similarity\n",
    "        else:\n",
    "            return (((1-THRESHOLD)/THRESHOLD)*similarity - 1)\n",
    "        \n",
    "    elif type == 'inverted':\n",
    "        return 1 - similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_of_individual_points(trajectory, resolution):\n",
    "    _images = [] \n",
    "    _points = np.array(trajectory)\n",
    "\n",
    "    for _index in range(0, int(len(_points)), resolution):\n",
    "        _images.append(drawing_bot.plot(training_mode=True, points=_points[_index:_index+resolution]))\n",
    "    clear_output(wait=True)\n",
    "    return _images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(template, drawing, random_action_prob, trajectory, individual_reward=True):\n",
    "    if individual_reward:\n",
    "        resolution = 10\n",
    "        images_of_individual_points = get_images_of_individual_points(trajectory, resolution)\n",
    "        rewards = np.array(image_processor.calc_rewards_for_individual_points(images_of_individual_points, drawing))\n",
    "        rewards = np.repeat(rewards, resolution, axis=0)\n",
    "        rewards = np.nan_to_num(rewards, nan=1)\n",
    "        #rewards = np.append(rewards, np.ones(len(trajectory)-len(rewards)))\n",
    "        model.train(rewards, random_action_prob)\n",
    "        del images_of_individual_points\n",
    "        clear_output(wait=True)\n",
    "        return np.mean(rewards), rewards\n",
    "    else:\n",
    "        similarity = image_processor(template, drawing=drawing)\n",
    "        if similarity is None:\n",
    "            return None\n",
    "        reward = calc_reward(similarity, type='default')\n",
    "        sub_rewards = model.train(reward, random_action_prob)\n",
    "        return reward, sub_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_assigned_reward_img(trajectory, rewards):\n",
    "    reward_assigned_drawing = drawing_bot.plot(training_mode=True, points=trajectory, color_assignment=rewards)\n",
    "    image_processor.save_image(reward_assigned_drawing, 'rewarded', 'rewarded_drawing')\n",
    "    image_processor.call_counter += 1\n",
    "    del reward_assigned_drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_cycle(cycle_index, num_of_cycles):\n",
    "    signal.alarm(30)\n",
    "\n",
    "    try:\n",
    "        trajectory, template = get_template()\n",
    "\n",
    "        random_action_prob = 0\n",
    "        RANDOM_CUTOFF = 200\n",
    "        if cycle_index < RANDOM_CUTOFF:\n",
    "            random_action_prob = np.random.random() * (0.01 - (cycle_index/(RANDOM_CUTOFF * 100))) + 0.00001# * pow(0.998, cycle_index)# - (cycle_index/(12*num_of_cycles))\n",
    "\n",
    "        #print(f'Exploration factor: {exploration_factor}')\n",
    "        adjusted_trajectory, adjusted_template = get_adjusted_trajectory(trajectory, random_action_prob)\n",
    "        simulated_trajectory, drawing = simulate_drawing(adjusted_trajectory)\n",
    "        reward, sub_rewards = fit_model(template, drawing, random_action_prob, trajectory, individual_reward=True)\n",
    "        if cycle_index % SAVE_IMAGE_FREQ == 0:\n",
    "            save_assigned_reward_img(simulated_trajectory, sub_rewards)\n",
    "            image_processor.save_image(drawing, 'original', 'drawing')\n",
    "        \n",
    "        del adjusted_trajectory, adjusted_template, simulated_trajectory, drawing, trajectory, template\n",
    "        \n",
    "        if not reward is None:\n",
    "            reward_log.append(reward)\n",
    "            print(f'{bcolors.HEADER}Cylce: {cycle_index}\\t{bcolors.ENDC}Exploration factor: {random_action_prob}\\t{bcolors.OKCYAN}Reward: {reward_log[-1]}{bcolors.ENDC}')\n",
    "        \n",
    "            if reward > 1:\n",
    "                return 1\n",
    "    \n",
    "    except TimeoutError as e:\n",
    "        if DEBUG_MODE:\n",
    "            raise\n",
    "        else:\n",
    "            print(f\"Timeout occurred: {e}\")\n",
    "\n",
    "    finally:\n",
    "        signal.alarm(0)  # Cancel the alarm\n",
    "        if 0:\n",
    "            gc.collect()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic | mean: 0.8464621901512146\tvar: 0.059674594551324844\tmin: 0.6601323485374451\tmax: 1.8164842128753662\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.7492 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9434 - loss: -0.0067\n",
      "\u001b[95mCylce: 6\t\u001b[0mExploration factor: 0.008670564919631175\t\u001b[96mReward: 0.9096457124528151\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_CYCLES = 500\n",
    "inital_weights = []\n",
    "\n",
    "for layer in model.critic.layers:\n",
    "    inital_weights.append(layer.get_weights()[0])\n",
    "\n",
    "for i in range(NUM_OF_CYCLES):\n",
    "    #print(f'Cylce: {i}')\n",
    "    if training_cycle(i, NUM_OF_CYCLES):\n",
    "        break\n",
    "    plt.close('all')\n",
    "\n",
    "#plot rewards and losses\n",
    "reward_log = gaussian_filter1d(reward_log, sigma=1)\n",
    "loss_history_actor = gaussian_filter1d(model.loss_history_actor.losses, sigma=2)\n",
    "loss_history_critic = gaussian_filter1d(model.loss_history_critic.losses, sigma=2)\n",
    "critic_mean = gaussian_filter1d(model.critic_mean_history, sigma=2)\n",
    "critic_var = gaussian_filter1d(model.critic_var_history, sigma=2)\n",
    "critic_min = gaussian_filter1d(model.critic_min_history, sigma=2)\n",
    "critic_max = gaussian_filter1d(model.critic_max_history, sigma=2)\n",
    "\n",
    "end_weights = []\n",
    "for layer in model.critic.layers:\n",
    "    end_weights.append(layer.get_weights()[0])\n",
    "\n",
    "#print(f'\\nInitial weights:\\n{inital_weights}')\n",
    "#print(f'\\n\\nWeights in the end:\\n{end_weights}\\n')\n",
    "\n",
    "plot_graph([loss_history_actor], ['actor loss'])\n",
    "plot_graph([loss_history_critic], ['critic loss'])\n",
    "plot_graph([reward_log], ['reward'])\n",
    "plot_graph([model.absolute_average_action_history], ['action average'])\n",
    "plot_graph([critic_mean, critic_var, critic_min, critic_max], ['Critic mean', 'Critic var', 'Critic min', 'Critic max'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
